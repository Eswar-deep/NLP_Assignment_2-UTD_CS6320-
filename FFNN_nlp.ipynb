{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTwPqAubRahs",
        "outputId": "86bc35ef-cf3b-4651-bf6a-6a26bedaedff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic FFnn"
      ],
      "metadata": {
        "id": "gxfnLiYoceIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner"
      ],
      "metadata": {
        "id": "1q9yl_65VCex"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "NUM_CLASSES = 5\n",
        "UNK = \"<UNK>\"\n",
        "\n",
        "DEFAULT_TRAIN = \"/content/training.json\"\n",
        "DEFAULT_VALID = \"/content/validation.json\"\n",
        "DEFAULT_TEST  = \"/content/test.json\"\n",
        "DEFAULT_OUT = \"/content/drive/MyDrive/vvkr_fnn\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QjuKunqvVCbw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running epochs in GPU**"
      ],
      "metadata": {
        "id": "P1dvFckrWfC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uy0oqOEqVCWR"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_json_any(path: str):\n",
        "    p = Path(path)\n",
        "    text = p.read_text(encoding=\"utf-8\").strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    if text[0] == \"{\":\n",
        "        return [json.loads(line) for line in text.splitlines() if line.strip()]\n",
        "    return json.loads(text)"
      ],
      "metadata": {
        "id": "el2oY52FVCTQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(s: str) -> List[str]:\n",
        "    return s.split()"
      ],
      "metadata": {
        "id": "Uwk3I6pMVCPI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(raw):\n",
        "    pairs = []\n",
        "    for e in raw:\n",
        "        toks = tokenize(e[\"text\"])\n",
        "        y = int(e[\"stars\"]) - 1\n",
        "        pairs.append((toks, y))\n",
        "    return pairs"
      ],
      "metadata": {
        "id": "k9gBrVpPVCHd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(train_pairs: List[Tuple[List[str], int]], min_freq: int = 1) -> Dict[str, int]:\n",
        "    from collections import Counter\n",
        "    c = Counter()\n",
        "    for toks, _ in train_pairs:\n",
        "        c.update(toks)\n",
        "    itos = [w for w, f in c.items() if f >= min_freq]\n",
        "    stoi = {w: i for i, w in enumerate(itos)}\n",
        "    stoi.setdefault(UNK, len(stoi))\n",
        "    return stoi"
      ],
      "metadata": {
        "id": "dZyxOxbeVRco"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bow_vectorize(toks: List[str], vocab: Dict[str, int]) -> np.ndarray:\n",
        "    vec = np.zeros(len(vocab), dtype=np.float32)\n",
        "    unk_idx = vocab[UNK]\n",
        "    for t in toks:\n",
        "        idx = vocab.get(t, unk_idx)\n",
        "        vec[idx] += 1.0\n",
        "    return vec"
      ],
      "metadata": {
        "id": "sq6QRQHrVRaa"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using Pytorch dataset n dataloader"
      ],
      "metadata": {
        "id": "255g7oePtyg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BOWDataset(Dataset):\n",
        "    def __init__(self, pairs: List[Tuple[List[str], int]], vocab: Dict[str, int]):\n",
        "        self.pairs = pairs\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        toks, y = self.pairs[idx]\n",
        "        x = bow_vectorize(toks, self.vocab)\n",
        "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "5OOvs1J_VRX8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**using sequential containers**"
      ],
      "metadata": {
        "id": "EZD4GL3JaBdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFNN(nn.Module):\n",
        "    def __init__(self, input_dim: int, layer_dims: List[int], dropout: float):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for h in layer_dims:\n",
        "            layers += [nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            in_dim = h\n",
        "        layers.append(nn.Linear(in_dim, NUM_CLASSES))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "TbUalaPWVRVl"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(model, loader, opt, device):\n",
        "    model.train()\n",
        "    total_loss, total, correct = 0.0, 0, 0\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = crit(logits, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * yb.size(0)\n",
        "        correct += (logits.argmax(-1) == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    return total_loss / total, correct / total"
      ],
      "metadata": {
        "id": "JCb9P28CVRSx"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss, total, correct = 0.0, 0, 0\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = crit(logits, yb)\n",
        "        total_loss += loss.item() * yb.size(0)\n",
        "        correct += (logits.argmax(-1) == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    return total_loss / total, correct / total"
      ],
      "metadata": {
        "id": "BqvtwrprVZyk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(model, loader, device, out_path):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    for xb, _ in loader:\n",
        "        xb = xb.to(device)\n",
        "        preds.extend((model(xb).argmax(-1).cpu() + 1).tolist())\n",
        "    Path(out_path).write_text(\"\\n\".join(map(str, preds)))\n",
        "    print(f\"[done] Predictions written to {out_path}\")\n"
      ],
      "metadata": {
        "id": "RC-C2wMIVZuk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optuna is exploring hyperparameters like:\n",
        "\n",
        "learning rate,\n",
        "hidden layer sizes\n",
        "dropout\n",
        "optimizer\n",
        "batch size\n",
        "patience"
      ],
      "metadata": {
        "id": "deeGNZqxcMd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, train_pairs, valid_pairs, vocab, args, device):\n",
        "\n",
        "    depth = trial.suggest_int(\"depth\", 1, 4)\n",
        "    hidden_choices = [64, 128, 256, 512, 768]\n",
        "    layer_dims = [trial.suggest_categorical(f\"h{i+1}\", hidden_choices) for i in range(depth)]\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.6)\n",
        "\n",
        "\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "    opt_name = trial.suggest_categorical(\"optimizer\", [\"adamw\", \"adam\", \"sgd\", \"rmsprop\"])\n",
        "    batch_size = trial.suggest_categorical(\"batch\", [32, 64, 128, 256])\n",
        "\n",
        "    patience = trial.suggest_int(\"patience\", 2, 5)\n",
        "\n",
        "    use_pin = (device.type == \"cuda\")\n",
        "    train_ds = BOWDataset(train_pairs, vocab)\n",
        "    valid_ds = BOWDataset(valid_pairs, vocab)\n",
        "    train_ld = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  pin_memory=use_pin)\n",
        "    valid_ld = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, pin_memory=use_pin)\n",
        "\n",
        "\n",
        "    model = FFNN(input_dim=len(vocab), layer_dims=layer_dims, dropout=dropout).to(device)\n",
        "\n",
        "    if opt_name == \"adamw\":\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif opt_name == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif opt_name == \"sgd\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    else:  # rmsprop\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    best_val = 0.0\n",
        "    wait = 0\n",
        "    for ep in range(args.epochs):\n",
        "        run_epoch(model, train_ld, optimizer, device)\n",
        "        _, val_acc = evaluate(model, valid_ld, device)\n",
        "\n",
        "        # report to Optuna includs pruning\n",
        "        trial.report(val_acc, ep)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        if val_acc > best_val:\n",
        "            best_val = val_acc\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                break\n",
        "\n",
        "    return best_val\n"
      ],
      "metadata": {
        "id": "PPxygT5aVZrE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "VBM4HkoLMcxj"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--train\", default=DEFAULT_TRAIN)\n",
        "    ap.add_argument(\"--valid\", default=DEFAULT_VALID)\n",
        "    ap.add_argument(\"--test\",  default=DEFAULT_TEST)\n",
        "    ap.add_argument(\"--epochs\", type=int, default=5)\n",
        "    ap.add_argument(\"--n_trials\", type=int, default=20)\n",
        "    ap.add_argument(\"--out_dir\", default=DEFAULT_OUT)\n",
        "\n",
        "    argv = [] if (\"ipykernel\" in sys.modules or \"COLAB_RELEASE_TAG\" in os.environ) else None\n",
        "    args = ap.parse_args(argv)\n",
        "\n",
        "    device = get_device()\n",
        "    print(f\"[device] {device} (cuda={torch.cuda.is_available()})\")\n",
        "\n",
        "    Path(args.out_dir).mkdir(parents=True, exist_ok=True)\n",
        "    train_raw = read_json_any(args.train)\n",
        "    valid_raw = read_json_any(args.valid)\n",
        "    test_raw  = read_json_any(args.test)\n",
        "    train_pairs, valid_pairs, test_pairs = make_pairs(train_raw), make_pairs(valid_raw), make_pairs(test_raw)\n",
        "\n",
        "    vocab = build_vocab(train_pairs)\n",
        "    print(f\"[vocab] size: {len(vocab)} (includes UNK)\")\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner(n_warmup_steps=2))\n",
        "    study.optimize(lambda tr: objective(tr, train_pairs, valid_pairs, vocab, args, device), n_trials=args.n_trials)\n",
        "\n",
        "    best = study.best_params\n",
        "    print(\"\\n[optuna] best val acc:\", study.best_value)\n",
        "    print(\"[optuna] best params:\", best)\n",
        "\n",
        "    # Save Optuna results\n",
        "    out_dir = Path(args.out_dir)\n",
        "    (out_dir / \"optuna_best_params.json\").write_text(json.dumps(best, indent=2))\n",
        "    study.trials_dataframe().to_csv(out_dir / \"optuna_trials.csv\", index=False)\n",
        "\n",
        "    # Final model with best config\n",
        "    depth = best[\"depth\"]\n",
        "    layer_dims = [best[f\"h{i+1}\"] for i in range(depth)]\n",
        "    dropout = best[\"dropout\"]\n",
        "    lr = best[\"lr\"]\n",
        "    batch_size = best[\"batch\"]\n",
        "\n",
        "    print(f\"[final config] depth={depth}, layers={layer_dims}, dropout={dropout}, lr={lr}, batch={batch_size}\")\n",
        "\n",
        "    all_train = train_pairs + valid_pairs\n",
        "    train_ds = BOWDataset(all_train, vocab)\n",
        "    test_ds  = BOWDataset(test_pairs, vocab)\n",
        "    train_ld = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    test_ld  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = FFNN(len(vocab), layer_dims, dropout).to(device)\n",
        "    opt = optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    best_state, best_acc = None, -math.inf\n",
        "    for ep in range(args.epochs):\n",
        "        tr_loss, tr_acc = run_epoch(model, train_ld, opt, device)\n",
        "        print(f\"[final][epoch {ep+1}/{args.epochs}] loss={tr_loss:.4f} acc={tr_acc:.4f}\")\n",
        "        if tr_acc > best_acc:\n",
        "            best_acc = tr_acc\n",
        "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best_state: model.load_state_dict(best_state)\n",
        "\n",
        "    model_path = out_dir / \"best_ffnn_bow.pt\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    preds_path = out_dir / \"test.out\"\n",
        "    predict(model, test_ld, device, preds_path)\n",
        "    print(f\"[done] Model saved to {model_path}\")\n",
        "    print(f\"[done] Predictions saved to {preds_path}\")\n",
        "    print(f\"[done] Optuna logs: {out_dir/'optuna_best_params.json'} and {out_dir/'optuna_trials.csv'}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here the optuna stops the entire trail if that underperform compared to other trials"
      ],
      "metadata": {
        "id": "N_UJF5TUYaPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if the model hit the plateaued then the patience will skip the epochs"
      ],
      "metadata": {
        "id": "u_0RsWmHZdwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here the patience 2,3,5 ..etc are like skipping epochs after 2,3..etc"
      ],
      "metadata": {
        "id": "-n4Yh8HxbQkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMrNIzkOq0Az",
        "outputId": "fed58d0b-1e97-469e-80eb-76908fe38389"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[device] cuda (cuda=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-26 18:00:10,377] A new study created in memory with name: no-name-c720b0da-1248-48fe-a2f9-719c00993f92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[vocab] size: 65667 (includes UNK)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-26 18:00:40,243] Trial 0 finished with value: 0.6325 and parameters: {'depth': 4, 'h1': 768, 'h2': 512, 'h3': 128, 'h4': 768, 'dropout': 0.4506802020741487, 'lr': 0.004002204900748412, 'weight_decay': 8.074185411738528e-06, 'optimizer': 'adam', 'batch': 32, 'patience': 3}. Best is trial 0 with value: 0.6325.\n",
            "[I 2025-10-26 18:00:54,903] Trial 1 finished with value: 0.61375 and parameters: {'depth': 4, 'h1': 128, 'h2': 512, 'h3': 512, 'h4': 512, 'dropout': 0.14983006931148932, 'lr': 0.00023896830822005952, 'weight_decay': 0.0003420367218940379, 'optimizer': 'rmsprop', 'batch': 64, 'patience': 3}. Best is trial 0 with value: 0.6325.\n",
            "[I 2025-10-26 18:01:09,239] Trial 2 finished with value: 0.535 and parameters: {'depth': 2, 'h1': 128, 'h2': 64, 'dropout': 0.4536060881879488, 'lr': 0.0028366557972284503, 'weight_decay': 1.8910492875298816e-05, 'optimizer': 'sgd', 'batch': 64, 'patience': 4}. Best is trial 0 with value: 0.6325.\n",
            "[I 2025-10-26 18:01:20,095] Trial 3 finished with value: 0.625 and parameters: {'depth': 2, 'h1': 64, 'h2': 256, 'dropout': 0.11399462515053857, 'lr': 0.0015051184480185179, 'weight_decay': 1.346732280260107e-05, 'optimizer': 'adam', 'batch': 64, 'patience': 2}. Best is trial 0 with value: 0.6325.\n",
            "[I 2025-10-26 18:01:41,705] Trial 4 finished with value: 0.6475 and parameters: {'depth': 1, 'h1': 512, 'dropout': 0.1171865130386747, 'lr': 0.0023006004363684803, 'weight_decay': 0.0004835154688741754, 'optimizer': 'adamw', 'batch': 256, 'patience': 5}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:02:03,525] Trial 5 finished with value: 0.6275 and parameters: {'depth': 1, 'h1': 512, 'dropout': 0.1691047369186688, 'lr': 0.002719087806744031, 'weight_decay': 0.008836691553174078, 'optimizer': 'adamw', 'batch': 128, 'patience': 4}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:02:13,760] Trial 6 pruned. \n",
            "[I 2025-10-26 18:02:21,784] Trial 7 pruned. \n",
            "[I 2025-10-26 18:02:35,133] Trial 8 pruned. \n",
            "[I 2025-10-26 18:02:58,951] Trial 9 finished with value: 0.64125 and parameters: {'depth': 1, 'h1': 768, 'dropout': 0.19754621576387119, 'lr': 0.0003886625642036369, 'weight_decay': 0.003462771962973006, 'optimizer': 'adam', 'batch': 128, 'patience': 5}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:03:18,531] Trial 10 finished with value: 0.63125 and parameters: {'depth': 3, 'h1': 256, 'h2': 128, 'h3': 64, 'dropout': 0.28200897125893437, 'lr': 0.0009745420756435776, 'weight_decay': 0.00010799792615021146, 'optimizer': 'adamw', 'batch': 256, 'patience': 5}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:03:39,686] Trial 11 finished with value: 0.62125 and parameters: {'depth': 1, 'h1': 512, 'dropout': 0.23141752275545793, 'lr': 0.00012834501699763838, 'weight_decay': 0.006785214251271272, 'optimizer': 'adam', 'batch': 256, 'patience': 5}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:04:03,062] Trial 12 finished with value: 0.6225 and parameters: {'depth': 2, 'h1': 768, 'h2': 768, 'dropout': 0.21459784649757951, 'lr': 0.0003327514176289996, 'weight_decay': 0.0009279601056612986, 'optimizer': 'rmsprop', 'batch': 128, 'patience': 5}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:04:22,856] Trial 13 finished with value: 0.63625 and parameters: {'depth': 1, 'h1': 256, 'dropout': 0.10463985005821395, 'lr': 0.001262307274397056, 'weight_decay': 9.794383091580308e-05, 'optimizer': 'adamw', 'batch': 256, 'patience': 4}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:04:46,791] Trial 14 finished with value: 0.62375 and parameters: {'depth': 3, 'h1': 768, 'h2': 768, 'h3': 768, 'dropout': 0.3796911825384258, 'lr': 0.000447261879573759, 'weight_decay': 0.0026846374424740393, 'optimizer': 'adam', 'batch': 128, 'patience': 5}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:04:59,941] Trial 15 pruned. \n",
            "[I 2025-10-26 18:05:21,880] Trial 16 finished with value: 0.63625 and parameters: {'depth': 1, 'h1': 512, 'dropout': 0.18177124984896503, 'lr': 0.0005872952893585005, 'weight_decay': 0.00044211103173478756, 'optimizer': 'adam', 'batch': 128, 'patience': 4}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:05:45,304] Trial 17 finished with value: 0.6275 and parameters: {'depth': 1, 'h1': 768, 'dropout': 0.2839656172176626, 'lr': 0.00019194251583737746, 'weight_decay': 3.869358387241596e-05, 'optimizer': 'rmsprop', 'batch': 256, 'patience': 5}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:06:05,527] Trial 18 finished with value: 0.61875 and parameters: {'depth': 3, 'h1': 256, 'h2': 768, 'h3': 512, 'dropout': 0.3800319452289597, 'lr': 0.001675992268402597, 'weight_decay': 0.003021935958933514, 'optimizer': 'adamw', 'batch': 32, 'patience': 4}. Best is trial 4 with value: 0.6475.\n",
            "[I 2025-10-26 18:06:23,686] Trial 19 finished with value: 0.635 and parameters: {'depth': 2, 'h1': 64, 'h2': 256, 'dropout': 0.10191740765586021, 'lr': 0.0006679173455491036, 'weight_decay': 0.0008081308843343376, 'optimizer': 'adam', 'batch': 256, 'patience': 5}. Best is trial 4 with value: 0.6475.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[optuna] best val acc: 0.6475\n",
            "[optuna] best params: {'depth': 1, 'h1': 512, 'dropout': 0.1171865130386747, 'lr': 0.0023006004363684803, 'weight_decay': 0.0004835154688741754, 'optimizer': 'adamw', 'batch': 256, 'patience': 5}\n",
            "[final config] depth=1, layers=[512], dropout=0.1171865130386747, lr=0.0023006004363684803, batch=256\n",
            "[final][epoch 1/5] loss=0.9462 acc=0.5749\n",
            "[final][epoch 2/5] loss=0.3949 acc=0.8744\n",
            "[final][epoch 3/5] loss=0.1473 acc=0.9652\n",
            "[final][epoch 4/5] loss=0.0466 acc=0.9933\n",
            "[final][epoch 5/5] loss=0.0164 acc=0.9994\n",
            "[done] Predictions written to /content/drive/MyDrive/vvkr_fnn/test.out\n",
            "[done] Model saved to /content/drive/MyDrive/vvkr_fnn/best_ffnn_bow.pt\n",
            "[done] Predictions saved to /content/drive/MyDrive/vvkr_fnn/test.out\n",
            "[done] Optuna logs: /content/drive/MyDrive/vvkr_fnn/optuna_best_params.json and /content/drive/MyDrive/vvkr_fnn/optuna_trials.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "files=pd.read_csv(\"/content/drive/MyDrive/vvkr_fnn/optuna_trials.csv\")\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-mtULvDpgYI",
        "outputId": "7e7da658-8c6d-48e0-fb8d-663105299caf"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    number    value              datetime_start           datetime_complete  \\\n",
            "0        0  0.63250  2025-10-26 18:00:10.377981  2025-10-26 18:00:40.243777   \n",
            "1        1  0.61375  2025-10-26 18:00:40.244856  2025-10-26 18:00:54.903338   \n",
            "2        2  0.53500  2025-10-26 18:00:54.904194  2025-10-26 18:01:09.239576   \n",
            "3        3  0.62500  2025-10-26 18:01:09.240470  2025-10-26 18:01:20.095308   \n",
            "4        4  0.64750  2025-10-26 18:01:20.096629  2025-10-26 18:01:41.705849   \n",
            "5        5  0.62750  2025-10-26 18:01:41.706795  2025-10-26 18:02:03.525387   \n",
            "6        6  0.40000  2025-10-26 18:02:03.526242  2025-10-26 18:02:13.760085   \n",
            "7        7  0.60625  2025-10-26 18:02:13.760881  2025-10-26 18:02:21.784248   \n",
            "8        8  0.51875  2025-10-26 18:02:21.784991  2025-10-26 18:02:35.132997   \n",
            "9        9  0.64125  2025-10-26 18:02:35.133771  2025-10-26 18:02:58.951913   \n",
            "10      10  0.63125  2025-10-26 18:02:58.952739  2025-10-26 18:03:18.531834   \n",
            "11      11  0.62125  2025-10-26 18:03:18.532737  2025-10-26 18:03:39.686863   \n",
            "12      12  0.62250  2025-10-26 18:03:39.687769  2025-10-26 18:04:03.062880   \n",
            "13      13  0.63625  2025-10-26 18:04:03.063774  2025-10-26 18:04:22.856426   \n",
            "14      14  0.62375  2025-10-26 18:04:22.857289  2025-10-26 18:04:46.791710   \n",
            "15      15  0.58500  2025-10-26 18:04:46.794144  2025-10-26 18:04:59.941539   \n",
            "16      16  0.63625  2025-10-26 18:04:59.942339  2025-10-26 18:05:21.880698   \n",
            "17      17  0.62750  2025-10-26 18:05:21.881625  2025-10-26 18:05:45.304905   \n",
            "18      18  0.61875  2025-10-26 18:05:45.305706  2025-10-26 18:06:05.527733   \n",
            "19      19  0.63500  2025-10-26 18:06:05.528826  2025-10-26 18:06:23.686676   \n",
            "\n",
            "                  duration  params_batch  params_depth  params_dropout  \\\n",
            "0   0 days 00:00:29.865796            32             4        0.450680   \n",
            "1   0 days 00:00:14.658482            64             4        0.149830   \n",
            "2   0 days 00:00:14.335382            64             2        0.453606   \n",
            "3   0 days 00:00:10.854838            64             2        0.113995   \n",
            "4   0 days 00:00:21.609220           256             1        0.117187   \n",
            "5   0 days 00:00:21.818592           128             1        0.169105   \n",
            "6   0 days 00:00:10.233843            64             4        0.546656   \n",
            "7   0 days 00:00:08.023367            32             4        0.554144   \n",
            "8   0 days 00:00:13.348006           128             1        0.308594   \n",
            "9   0 days 00:00:23.818142           128             1        0.197546   \n",
            "10  0 days 00:00:19.579095           256             3        0.282009   \n",
            "11  0 days 00:00:21.154126           256             1        0.231418   \n",
            "12  0 days 00:00:23.375111           128             2        0.214598   \n",
            "13  0 days 00:00:19.792652           256             1        0.104640   \n",
            "14  0 days 00:00:23.934421           128             3        0.379691   \n",
            "15  0 days 00:00:13.147395           256             2        0.218103   \n",
            "16  0 days 00:00:21.938359           128             1        0.181771   \n",
            "17  0 days 00:00:23.423280           256             1        0.283966   \n",
            "18  0 days 00:00:20.222027            32             3        0.380032   \n",
            "19  0 days 00:00:18.157850           256             2        0.101917   \n",
            "\n",
            "    params_h1  params_h2  params_h3  params_h4  params_lr params_optimizer  \\\n",
            "0         768      512.0      128.0      768.0   0.004002             adam   \n",
            "1         128      512.0      512.0      512.0   0.000239          rmsprop   \n",
            "2         128       64.0        NaN        NaN   0.002837              sgd   \n",
            "3          64      256.0        NaN        NaN   0.001505             adam   \n",
            "4         512        NaN        NaN        NaN   0.002301            adamw   \n",
            "5         512        NaN        NaN        NaN   0.002719            adamw   \n",
            "6         512      256.0      128.0      256.0   0.000318              sgd   \n",
            "7          64       64.0      256.0      512.0   0.002564            adamw   \n",
            "8         768        NaN        NaN        NaN   0.000708              sgd   \n",
            "9         768        NaN        NaN        NaN   0.000389             adam   \n",
            "10        256      128.0       64.0        NaN   0.000975            adamw   \n",
            "11        512        NaN        NaN        NaN   0.000128             adam   \n",
            "12        768      768.0        NaN        NaN   0.000333          rmsprop   \n",
            "13        256        NaN        NaN        NaN   0.001262            adamw   \n",
            "14        768      768.0      768.0        NaN   0.000447             adam   \n",
            "15        512      128.0        NaN        NaN   0.000105            adamw   \n",
            "16        512        NaN        NaN        NaN   0.000587             adam   \n",
            "17        768        NaN        NaN        NaN   0.000192          rmsprop   \n",
            "18        256      768.0      512.0        NaN   0.001676            adamw   \n",
            "19         64      256.0        NaN        NaN   0.000668             adam   \n",
            "\n",
            "    params_patience  params_weight_decay     state  \n",
            "0                 3             0.000008  COMPLETE  \n",
            "1                 3             0.000342  COMPLETE  \n",
            "2                 4             0.000019  COMPLETE  \n",
            "3                 2             0.000013  COMPLETE  \n",
            "4                 5             0.000484  COMPLETE  \n",
            "5                 4             0.008837  COMPLETE  \n",
            "6                 3             0.000979    PRUNED  \n",
            "7                 3             0.000003    PRUNED  \n",
            "8                 2             0.001775    PRUNED  \n",
            "9                 5             0.003463  COMPLETE  \n",
            "10                5             0.000108  COMPLETE  \n",
            "11                5             0.006785  COMPLETE  \n",
            "12                5             0.000928  COMPLETE  \n",
            "13                4             0.000098  COMPLETE  \n",
            "14                5             0.002685  COMPLETE  \n",
            "15                5             0.000188    PRUNED  \n",
            "16                4             0.000442  COMPLETE  \n",
            "17                5             0.000039  COMPLETE  \n",
            "18                4             0.003022  COMPLETE  \n",
            "19                5             0.000808  COMPLETE  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/vvkr_fnn/test.out\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    lines = f.read().strip().splitlines()\n",
        "\n",
        "print(f\" Loaded {len(lines)} predictions.\")\n",
        "print(\"First 10 predictions:\", lines[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8CpEXywppEw",
        "outputId": "0fc0af96-bb68-44fa-a494-629c41cd928f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded 800 predictions.\n",
            "First 10 predictions: ['2', '3', '3', '3', '3', '2', '3', '3', '2', '1', '2', '1', '1', '2', '2', '3', '2', '3', '3', '3', '1', '2', '3', '2', '1', '2', '2', '2', '3', '3', '3', '2', '1', '2', '3', '3', '3', '2', '2', '3', '3', '3', '2', '3', '2', '2', '3', '2', '2', '3']\n"
          ]
        }
      ]
    }
  ]
}